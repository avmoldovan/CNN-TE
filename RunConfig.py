settings = {
    'USPS' : {
        'dataset': 'USPS',
        'lr': 0.008,
        'momentum' : 0.0,
        'weight_decay' : 0.0,
        'lr_decay' : 0.1,
        'lr_decay_epochs': 2,
        'data' : './/data/usps',
        'dropout1' : 0.25,
        'dropout2' : 0.5,
        'resume' : False,
        'num_classes' : 10,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNet-USPS',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        'run_title' : 'noTE-usps-mom0-lrd0-b100-do1025-d20-wd0-lr0001-gpu-60ep',

        'trainingset_size' : 60000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 60,#90,
        'pretrained': False,
        'pretrained_url': 'noTE-subset5k-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 6000,
        'batch_size' : 100,
        'use_subset' : True,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 1.0,
        'tr2' : 0.9,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 500,
        'clean_window': False,
        'fc8rate': 0,
        'save_model': False,
        'forward': True,

        'useTIE' : True,
        'withte': True,
        'fc7rate': 0,
        'fc7te' : True,
        'debug' : True
    },
    'SVHN' : {
        'dataset': 'SVHN',
        'lr': 0.001,
        'momentum' : 0.9,
        'weight_decay' : 0.1,
        'lr_decay' : 0.0,
        'lr_decay_epochs': 20,
        'data' : '.\\data',
        'dropout1' : 0.3,
        'dropout2' : 0.0,
        'resume' : False,
        'num_classes' : 10,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNetFB',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        #'run_title' : 'CF10-TEhookbw-fc8-smx-WeqWmulEye-TEWINDOW-TR0.5-TR20.9-telen4096-noROLL-mom09-lrd0.1by20-b128-do10-do20-wd00005-lr0.01-gpu-35ep',
        'run_title' : 'CF10-TEhookbw-fc8-smx-WeqWmulEye1.2-epoch-TR1.0-TR20.9-telen4096-rolling-mom09-lrd0.1by20-b128-do10-do20-wd00005-lr0.01-cpu-35ep',


        'trainingset_size' : 50000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 150,#90,
        'pretrained': False,
        'pretrained_url': 'noTE-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 512,
        'batch_size' : 200,
        'use_subset' : False,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 1.0,
        'tr2' : 0.9,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 4096,
        'clean_window': False,
        'fc8rate': 0,
        'save_model': False,
        'forward': True,

        'withte': True,
        'fc7rate': 0,
        'fc7te' : True,
        'debug' : True
    },
    'STL10' : {
        'dataset': 'STL10',
        'lr': 0.001,
        'momentum' : 0.9,
        'weight_decay' : 0.0,
        'lr_decay' : 0.0,
        'lr_decay_epochs': 20,
        'data' : '.\\data',
        'dropout1' : 0.0,
        'dropout2' : 0.0,
        'resume' : False,
        'num_classes' : 10,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNetFB',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        #'run_title' : 'CF10-TEhookbw-fc8-smx-WeqWmulEye-TEWINDOW-TR0.5-TR20.9-telen4096-noROLL-mom09-lrd0.1by20-b128-do10-do20-wd00005-lr0.01-gpu-35ep',
        'run_title' : 'CF10-TEhookbw-fc8-smx-WeqWmulEye1.2-epoch-TR1.0-TR20.9-telen4096-rolling-mom09-lrd0.1by20-b128-do10-do20-wd00005-lr0.01-cpu-35ep',


        'trainingset_size' : 50000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 150,#90,
        'pretrained': False,
        'pretrained_url': 'noTE-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 512,
        'batch_size' : 200,
        'use_subset' : False,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 1.0,
        'tr2' : 0.9,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 4096,
        'clean_window': False,
        'fc8rate': 0,
        'save_model': False,
        'forward': True,

        'withte': True,
        'fc7rate': 0,
        'fc7te' : True,
        'debug' : True
    },
    'CIFAR10' : {
        'dataset': 'CIFAR10',
        'lr': 0.01,
        'momentum' : 0.9,
        'weight_decay' : 0.0005,
        'lr_decay' : 0.1,
        'lr_decay_epochs': 20,
        'data' : '.\\data',
        'dropout1' : 0.0,
        'dropout2' : 0.0,
        'resume' : False,
        'num_classes' : 10,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNetFB',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        #'run_title' : 'CF10-TEhookbw-fc8-smx-WeqWmulEye-TEWINDOW-TR0.5-TR20.9-telen4096-noROLL-mom09-lrd0.1by20-b128-do10-do20-wd00005-lr0.01-gpu-35ep',
        'run_title' : 'CF10-TEhookbw-fc8-smx-WeqWmulEye1.2-epoch-TR1.0-TR20.9-telen4096-rolling-mom09-lrd0.1by20-b128-do10-do20-wd00005-lr0.01-cpu-35ep',


        'trainingset_size' : 50000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 35,#90,
        'pretrained': False,
        'pretrained_url': 'noTE-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 512,
        'batch_size' : 128,
        'use_subset' : False,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 1.0,
        'tr2' : 0.9,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 512,
        'clean_window': False,
        'fc8rate': 0,
        'save_model': False,
        'forward': True,

        'withte': True,
        'fc7rate': 0,
        'fc7te' : True,
        'debug' : True
    },
    'CIFAR100' : {
        'dataset': 'CIFAR100',
        'lr': 0.01,
        'momentum' : 0.9,
        'weight_decay' : 0.,#0.0005,
        'lr_decay' : 0.,#0.1,
        'lr_decay_epochs': 30,
        'data' : '.\\data',
        'dropout1' : 0.,#0.5,
        'dropout2' : 0.,#0.5,
        'resume' : False,
        'num_classes' : 100,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNetFB',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        'run_title' : 'CF10tiny-NOTE-smxG01-telen128-withparams-mom09-wd0-lrd0-b128-do0-lr0001-gpu-60ep',


        'trainingset_size' : 50000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 2,#90,
        'pretrained': False,
        'pretrained_url': 'noTE-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 3000,
        'batch_size' : 128,
        'use_subset' : False,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 0.01,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 512,
        'clean_window': False,
        'fc8rate': 0,
        'save_model': False,
        'forward': True,

        'withte': False,
        'fc7rate': 0,
        'fc7te' : True,
        'debug' : False
    },
    'fashionMNIST' : {
        'dataset': 'FashionMNIST',
        'lr': 0.008,
        'momentum' : 0.0,
        'weight_decay' : 0.0,
        'lr_decay' : 0.1,
        'lr_decay_epochs': 2,
        'data' : './/data/fashionMNIST',
        'dropout1' : 0.25,
        'dropout2' : 0.5,
        'resume' : False,
        'num_classes' : 10,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNet-FashionMNIST',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        'run_title' : 'withTE-fashionmnist-subset-withparams-b4-do05-lr001-gpu-20ep',

        'trainingset_size' : 60000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 60,#90,
        'pretrained': False,
        'pretrained_url': 'noTE-subset5k-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 60000,
        'batch_size' : 100,
        'use_subset' : False,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 1.0,
        'tr2' : 0.9,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 500,
        'clean_window': False,
        'fc8rate': 0,
        'save_model': False,
        'forward': True,

        'withte': True,
        'fc7rate': 0,
        'fc7te' : True,
        'debug' : True
    },
    'SMALLMNIST' : {
        'dataset': 'MNIST',
        'lr': 0.001,
        'momentum' : 0.9,
        'weight_decay' : 0.0005,
        'lr_decay' : 10,
        'data' : '.\\data',
        'dropout1' : 0.25,
        'dropout2' : 0.5,
        'resume' : False,
        'num_classes' : 10,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNetFB',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        'run_title' : 'withTE-mnist-C10-withparams-tel512-mom09-wd00005-lrd10-b4-do05-lr001-gpu-20ep',

        'trainingset_size' : 50000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 20,#90,
        'pretrained': False,
        'pretrained_url': 'noTE-subset5k-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 50000,
        'batch_size' : 64,
        'use_subset' : False,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 0.9,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 512,
        'fc8rate': 0,
        'save_model': False,

        'fc7rate': 0,
        'fc7te' : True,
        'debug' : True
    },
    'MNIST' : {
        'dataset': 'MNIST',
        'lr': 0.001,
        'momentum' : 0.9,
        'weight_decay' : 0.0005,
        'lr_decay' : 10,
        'data' : './/data/mnist',
        'dropout1' : 0.25,
        'dropout2' : 0.5,
        'resume' : False,
        'num_classes' : 10,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNetFB',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        'run_title' : 'withTE-mnist-C10-withparams-tel512-mom09-wd00005-lrd10-b4-do05-lr001-gpu-20ep',

        'trainingset_size' : 50000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 20,#90,
        'pretrained': False,
        'pretrained_url': 'noTE-subset5k-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 50000,
        'batch_size' : 10,
        'use_subset' : False,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 0.9,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 512,
        'fc8rate': 0,
        'save_model': False,

        'fc7rate': 0,
        'fc7te' : True,
        'debug' : True
    },
    'tiny' : {
        'dataset': 'TINYIMAGENET',
        'lr': 0.001,
        'momentum' : 0.9,
        'weight_decay' : 0.0005,
        'lr_decay' : 0.1,
        'lr_decay_epochs': 30,
        'data' : './/data/tiny-imagenet-200',
        'dropout1' : 0.5,
        'dropout2' : 0.5,
        'resume' : False,
        'num_classes' : 200,
        'start_epoch' : 0,
        'seed' : None,
        'variable_batch_size' : False,
        'world_size' : 1, #int(os.environ["WORLD_SIZE"])
        'rank': 0,
        'multiprocessing_distributed' : False,
        'distributed' : False,
        'ngpus_per_node' : 0, #torch.cuda.device_count()
        'workers' : 0,
        'dist_url' : None,
        'arch' : 'AlexNetFB',
        'shuffle_validation' : False,
        'bestmodel_name' : 'bestmodel',
        'checkpoint_name' : 'checkpoint',
        'run_title' : 'ANTIN-withparams-tel512-mom09-wd00005-lrd10-b4-do05-lr001-gpu-20ep',

        'trainingset_size' : 200000,
        'gpu' : 'cpu', #'cuda:0',
        'epochs': 90,
        'pretrained': False,
        'pretrained_url': 'noTE-subset5k-withparams-mom09-wd00005-lrd10-b128-do05-lr001-gpu-90ep-model_best.pth.tar',#'mom0-wd0-lrd0-b128-do0-gpu-baseretrain-noTE-noSMX-300ep-model_best.pth.tar',
        #'pretrained_url': 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar', # last 4 layers with TE
        #'pretrained_url' : 'mom0-wd00-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth (1).tar',
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-model_best.pth.tar',  # leave empty to load the pytorch one
        #'pretrained_url': 'mom9-wd0005-b128-gpu-baseretrain-wo-TE-wo-Freeze-checkpoint.pth.tar',  # leave empty to load the pytorch one
        # 'pretrained_url' : 'mom9-wd0005-b128-gpu-baseretrain-checkpoint.pth.tar',
        'base_retrain': True,
        'partial_freeze': False,
        'trainsubset': 2000,
        'batch_size' : 128,
        'use_subset' : False,
        'subset_classes' : None,
        'print_freq' : 1,
        'evaluate' : False,
        #new
        'tr1' : 0.9,
        'te_events_batch_multiple' : 1,
        'rolling_te_window' : False,
        'suffix' : '',
        'out_to_file' : False,
        'skip_first' : 10,
        'te_length': 512,
        'fc8rate': 0,
        'save_model': False,

        'fc7rate': 0,
        'fc7te' : True,
        'debug' : True
    },
}